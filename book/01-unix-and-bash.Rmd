# Using UNIX-like computers and mastering the command shell {#unix-and-shell}

Most programs in bioinformatics are written for UNIX-like operating systems like Linux. Moreover,
they are usually controlled from the \index{command line}command line (\index{CLI}CLI) and not from
a \index{graphical interface}graphical interface (\index{GUI}GUI).

\index{UNIX}UNIX and it's derivatives have a long history as an operating system by programmers for
programmers.  This makes UNIX different from commercial operating systems and there is a clear
philosophy behind many aspects of behavior of a computer running UNIX. That being said, a modern
UNIX-like operating system like Linux is in many ways similar to e.g. Apple's OS X or Windows and is
fully controllable via a graphical interface. However, behind the graphical interface the tools many
long-time users have come to love still remain. Apple's OS X is in this way similar to e.g. Linux by
being a UNIX at its core, with a proprietary graphical interface which is a commercial, non-free
program. 

## Interacting with UNIX-like operating systems from commercial operating systems {#interacting-with-unix}

In scientific computing, the most common way to connect to a computing cluster running Linux, is to
use \index{SSH}Secure Shell (SSH). 

### Connecting from a UNIX-like computer (Linux or Mac OS X) {#connecting-from-unix}

SSH\index{SSH} is a command-line tool available in all Linux distributions and in OS X. You connect
like this:

```
ssh user@rackham.uppmax.uu.se
```

And your local command-line session is exchanged for one at the cluster.

### Connecting from a Windows computer {#connecting-from-windows}

It's a little bit more complicated with Windows computers, because there's no ssh program directly
available. There are some options though. At UPPMAX they recommend the
\index{MobaXterm}[MobaXterm](http://mobaxterm.mobatek.net/) program (see [UPPMAX
documentation](http://www.uppmax.uu.se/support/user-guides/guide--first-login-to-uppmax/)). Another
popular program is \index{PuTTY}[PuTTY](https://putty.org/).

There are also Bash implementations for Windows, e.g.
\index{Cygwin}[Cygwin](https://www.cygwin.com/) and the command line interface that comes with
\index{Git for Windows}[Git for Windows](https://git-scm.com/download/win).

(I also came across a [blog post describing Windows 10's inbuilt Bash
shell](https://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/).)

### SSH public key authentication {#ssh-public-key-authentication}

There are two ways of \index{SSH, authentication}authentication in SSH: the normal
username/password and \index{public key authentication}public key authentication. The latter is
using \index{public-key cryptography}[public-key
cryptography](https://en.wikipedia.org/wiki/Public-key_cryptography), also known as
\index{asymmetric cryptography}asymmetric cryptography. In public-key cryptography each user has a
*pair* of keys, which each can be used to encrypt a message. If a message is encrypted by one of the
keys, it can only be decrypted with the *other* key. The two keys are treated differently, so that
one is kept secret (the \index{private key}*private* key) while the other can be publicly
distributed (the \index{public key}*public* key). Anyone on the Internet can download a public key
from another user, and use this to encrypt a message and send to the owner of the public key which
is the only user that can decrypt it, using its private key.

Besides being useful for encrypting messages, public-key cryptography can also be used to verify a
user or computer is actually what it personates as. This relies on encrypting non-secret messages
with the private key. If I would send a message containing, say, the current time and date,
and send it to the user or computer, it could return the message encrypted with its *private* key.
If the returned message is possible to decrypt with its *public* key yielding the original message,
its proof that the message was in the hands of the user or computer and is hence proof of
authenticity.

This mechanism for authentication is what SSH uses in its public-key authentication mode. Many argue
this is a safer mode of authentication, as long as users keep their private keys private and safe,
but it also has other advantages primarily that you can save typing your password each time you log
on to a computer. To keep the private key private it is important to protect it with a good
\index{passphrase}*passphrase*, which is a normal, \index{symmetric cryptography}[symmetric
cryptography](https://en.wikipedia.org/wiki/Public-key_cryptography), key, used to encrypt and
decrypt the key. Each time you logon using public-key authentication, you will be asked to type in
your passphrase to the key instead of the password to the computer. So what is gained by that?
Nothing, unless you run an \index{SSH-agent}SSH-agent, which is a program that keeps your key in
memory so you only need to type in your passphrase once after each boot. 

To create a key-pair, you run:

```
ssh-keygen
```

You will be asked to provide a passphrase -- make sure it's *strong* and something you're *not using
on the Internet*.

#### Running an SSH-agent {#ssh-agent}

The SSH-agent is usually started automatically on a Linux machine, but on OS X it requires (I
believe) that you add the following to a file called `~/.ssh/config` (which might not yet exist).
(This is a \index{text file}*text file*; see \@ref(text-editors) for how to work with text files.)

```
Host *
    AddKeysToAgent yes
```

(The `.ssh` directory should be writable only for the owner, but can be readable and executable for
the group and the world (see \@ref(users-groups-permissions) below). Set permissions for the config
file similarly, i.e. read and write for the owner, read for everybody else.)

See [this
page](https://www.reddit.com/r/osx/comments/52zn5r/difficulties_with_sshagent_in_macos_sierra/) if
you don't get it working right away.

#### Running an SSH-agent on a Windows machine {#ssh-agent-windows}

## Using the Linux command line {#linux-cli}

The Linux command line is a program called the \index{shell}*shell*, and exists in different
versions. The most popular is probably \index{Bash}Bash (short for *B*ourne *a*gain *sh*ell) a
derivative of the original \index{Bourne shell}*Bourne shell* Sh. Together with \index{Korn
shell}*Korn shell*, Sh and Bash forms a family with similar syntax. A second family started with
\index{C shell}*C shell* Csh, which aimed at being more similar in syntax to the *C* programming
language. In this book, we're going to focus solely on Bash.

The shell is both a way of interacting interactively with the computer and a programming language, a
\index{scripting}\index{script}*scripting* language. When you use the shell interactively you
execute commands and programs and a shell script is nothing else than a set of commands saved for
later, though often generalized with variables etc. to be more useful.

There are many free sources of information available, one of them the classic [Bash Guide for
Beginners](http://www.tldp.org/LDP/Bash-Beginners-Guide/html/) [@garrels_bash_2008] from "The
Linux Documentation Project" (tldp).

### Getting help {#cli-getting-help}

The classical way of program authors to provide help to users is via manual ("man") pages, readable
with the \index{Man}Man command. To read the man page for e.g. the Find program you:

```
man find
```

The man command uses the \index{More}More command to show the content page by page. Step through
pages with the space key, search with `/` followed by a string and exit by pressing `q`.

Today it's more common to integrate help in the program and make it available with a flag, usually
`--help` or `-h`. In many cases, you get more than one page of output, so you might want to pipe the
output to More to read page by page.

```
wget --help|more
```

For complex programs doing many different things it has become increasingly popular to modularise
program invocation and help. A typical example is \index{Git}Git, which has one overall help plus
individual help for each type of thing you can do with the program.

```
git --help
git clone --help
```

In this particular example, you're actually taken to the manual page for `git clone` in the latter
of the two commands.

### The environment {#bash-environment}

Your \index{environment}*environment* is a rather abstract concept. One could say that it
encompasses all the settings you have made to make work effective. When you start computing in a
UNIX environment, you're likely to just accept whatever default settings are there, but with time
you might become more and more picky about settings and will start to change them and, when logging
in to a new computer, you will try to as soon as possible get that set the way you want it.

Your environment is configured through various files, some of a general character, others specific
for a program or a set of programs. Many of these files have names that start with a `.` which, in
most cases, make them \index{hidden files}*hidden* so they do not show up e.g. in normal directory
listings. The purpose of hiding files is to make it a little bit more difficult to change things
that might have negative effects if not done properly.

#### Variables {#bash-variables}

One key part of configuration is to set \index{variable}variables, in particular 
\index{environment variable}*environment variables*, that are read by different programs and affect
how they work.  Variables are set with an equal sign: `var=something`, sets the variable "var" to
contain the text "something". The value is retrieved by putting a dollar before the variable name:
`$var`, see examples below.

The difference between normal variables and *environment* variables is that the latter are more
visible to other programs. This can be illustrated by running the following commands, which also
shows the syntax of setting variables at the Bash command prompt and checking their contents:

```
# Set a variable
var='Hello world'
# A variable is visible in the current shell:
echo $var
# But not in a subshell
bash    # Starts a subshell
echo $var
exit    # Exits the subshell 
echo $var

# If you export a variable, it becomes an environment variable and is visible in subshells:
export var
bash    # Starts a subshell
echo $var
exit    # Exits the subshell
echo $var
```

Since a \index{subshell}subshell is started every time you run a program, variables need to be
exported if they are to be visible by the program. It is hence only *environment* variables that are
visible to programs you start from the command line.

A classical configuration file consists of a number of definitions of environment variables (plus in
some cases other kinds of mechanisms) and can be seen as an executable text file, a
\index{script}script. The problem with this is that a subshell is started for each new program run,
and variables will be set in the subshell but *not in the current shell*. To run a configuration
script in the current shell instead of in a subshell, you need to \index{source}*source* it by
preceding it with `source`. An example illustrates this:

```
# Create a small config file
echo "export var='New value for var'" > /tmp/my_config
# Run without sourcing
/bin/bash /tmp/my_config
# Now check what var is set to
echo $var

# Source the file and see what var is set to after
source /tmp/my_config
echo $var
```

Perhaps you noted in the example above that I used both single \index{quotes}quotes `'` and double
quotes `"`.  They have almost the same meaning. Both types quotes text, the difference is that
within double quotes, variables are extrapolated, but they are not in single quotes:

```
var='Hello world'
echo "$var"     # Types out Hello world
echo '$var'     # Types out $var
```

#### Configuration files {#bash-config-files}

There are two main \index{configuration files}configuration files for Bash:
\index{.bash\_profile}`.bash_profile` and \index{.bashrc}`.bashrc`. The former is sourced when you
log in whereas the latter is sourced each time a subshell is started. This means that `.bashrc` is
sourced for every program you run since programs are run in subshells.

Of particular interest is the \index{PATH environment variable}`PATH` environment variable. This
contains a list of directories, separated by `:` characters, in which Bash will search for programs.
When you call e.g. Grep, Bash will look through the list of directories in your `PATH` for an
executable file called "grep" and run that for you.

Since environment variables are visible in subshells, they need only be set when you log in and are
hence best defined in `.bash_profile`. Other configurations are better placed in `.bashrc`. An
example is \index{alias}`alias` definitions. Today, it is quite common that alias definitions are
placed in a file of their own `.bash_aliases` which is sourced in `.bashrc`.

When you first log on to a UNIX machine it is common that `.bash_profile` and `.bashrc` already
exist, with some default content.

### Pipelines {#pipelines}

The word \index{pipeline}"pipeline" can mean slightly different things in computing. The most
original meaning comes from the UNIX shell, where it means that you literally connect the output of
one command as input to the next in a chain^[When the word "pipeline" is used in computational
biology, it's usually used symbolically and means that in order to produce a certain output you need
to run several programs in succession. A better term for this is \index{workflow}*workflow*.]. 

To truly understand what's going on, you need to know about the three different "channels" that each
UNIX command has: \index{standard input}\index{STDIN}standard input (STDIN), \index{standard
output}\index{STDOUT}standard output (STDOUT) and \index{standard error}\index{STDERR}standard error
(STDERR). By default, STDIN is connected to your keyboard and the other two to your screen. The
difference between STDOUT and STDERR is that the latter is reserved for error messages from a
program, whereas the former is used for expected output. The channels can be
\index{redirection}redirected to files, which is done with `<` for STDIN, `>` for STDOUT and `2>`
for STDERR. In principle, a command hence looks like this:

```
cat < input_file > output_file 2> error_message_file
```

The above command reads `input_file` and sends that to `output_file`; if an error occurs, messages
will be written to `error_message_file`. (The example is a bit constructed, because if you don't
redirect STDIN, `cat` actually reads one or more files on the command line, e.g.: `cat file1 file2
file3 > concatenated_file`.)

The \index{pipe}pipe character \index{|}`|` connects STDOUT from one command, to STDIN for the next, which makes it
possible to modify the output of one command and form a *pipeline*. A very common example is to
place `more` as the last output of a command that produces a lot of output, so you can read the
output page by page.

```
# Find all files ending with `.tsv` and check output page by page with `more`.
find . -name "*.tsv" | more
```

Pipelines can be arbitrarily long and often contain programs like \index{Grep}grep (scans for text
patterns), \index{Sed}Sed` or \index{AWK}AWK (modifies text), `tail -f` (follow output when it's
being produced). This is in line with the \index{UNIX philosophy}*UNIX philosophy* that programs
should do one thing and do it well, leaving other things for other programs.

### Job control {#job-control}

`&`, `bg`, `fg`, `jobs` and &lt;ctrl&gt;-Z.

## Users, files, directories and file systems {#users-files-and-filesystems}

### Users, groups and permissions {#users-groups-permissions}

A *user* in a UNIX system is what you log in as. Any files you create when you're working in the
computer will be *owned* by this user plus a *group*. Whereas you can only be one user (unless you
have multiple accounts), each user can belong to more than one group. The group that owns a file
will be your *default group*, unless you change this. In a typical Linux system, your default group
is named like your user and you're the only user belonging to this group.

It's common, however, to create groups to enable collaboration since users and groups are used to
control access to files. You can e.g. create a group for a project and make sure that all files that
should be accessible to members of the project are owned by this group.

When you list a directory in long format, you can see user, group and permissions, together with
many other details:

```
ls -l
-rw-r--r-- 1 dl dl  2526 dec 21 15:54 00-data-organization.Rmd
-rw-r--r-- 1 dl dl 15216 dec 21 16:03 01-unix-and-bash.Rmd
-rw-r--r-- 1 dl dl  4902 dec 21 15:54 02-uppmax.Rmd
-rw-r--r-- 1 dl dl   138 dec  4 10:29 03-regexps.Rmd
-rw-r--r-- 1 dl dl   365 dec 21 15:54 04-automation-with-snakemake.Rmd
-rw-r--r-- 1 dl dl   104 dec  4 10:29 05-notes-on-annotation.Rmd
-rw-r--r-- 1 dl dl   789 dec  6 09:57 06-tidyverse-intro.Rmd
-rw-r--r-- 1 dl dl    65 dec  6 09:57 10-appendices.Rmd
-rw-r--r-- 1 dl dl  2434 dec 21 15:54 11-bash-command-appendix.Rmd
-rw-r--r-- 1 dl dl    56 dec 21 15:54 12-computer-terminology.Rmd
-rw-r--r-- 1 dl dl    91 dec 21 15:54 13-references.Rmd
drwxr-xr-x 4 dl dl  4096 dec 21 15:57 _book
-rw-r--r-- 1 dl dl  2103 dec  6 09:57 eemis-compbio.bib
lrwxrwxrwx 1 dl dl    15 dec 21 15:54 fundamentals_of_computational_biology.pdf -> _book/_main.pdf
drwxr-xr-x 2 dl dl  4096 dec 21 15:54 img
-rw-r--r-- 1 dl dl   907 dec  6 09:57 index.Rmd
-rw-r--r-- 1 dl dl     0 dec  4 09:42 packages.bib
-rw-r--r-- 1 dl dl  1103 dec  6 09:57 README.md
```

The user is the fourth column and the group the fifth.

The first column, looking like `-rw-r--r--` is information about which type of file it is: `-` is a
normal file, `d` a directory and `l` a symbolic link (see \@ref(symlinks)). Next comes permissions
for owner, group and everybody else (the *world*) as triplets: `r` for read, `w` for write and `x`
or `s` for executable. The string `-rw-r--r--` in other words means read and writable for the user
and only readable for anybody else in the group as well as the world. Each part of this string is
called a *bit*.

The third bit, the executable, behaves differently for normal files and directories. For normal
files it means the operating system will treat it like a program and run it if you tell it to. For
directories it means you can `cd` into this directory and use it as your working directory. If
there's an `s` instead of an `x` here it's yet again different between normal files and directories.
For normal files an `s` means that the program will be executed as the owner of the file (`s` in the
first triplet, i.e. as the fourth character) or group (`s` in the second triplet). This is commonly
used for administrative programs that need more permissions than a normal user has. For directories,
you mostly see `s` bit set on the group, which is a way of saying that all files and directories in
this directory will belong to the same group as the directory with the `s` bit set. This is hence an
excellent way of controlling access for a project directory. (In the UPPMAX computers, the `/proj/`
directories are by default owned by the corresponding group and the `s` bit is set.

Ownership, both user and group, is controlled with the `chown` and `chgrp` commands (`chown` can
change both user and group). The following will change ownership of the file `file` to the `dl` user
and the `projects` group:

```
chgrp dl:projects file
```

To manipulate permissions of a file or directory, you use the `chmod` command. The most practical
syntax for this is the *symbolic*, which works like this:

```
# Add writeability to the group
chmod g+w file
# Remove readability from the world
chmod o-r file
# Set the user's permissions to read, write and execute
chmod u=rwx file
```

### File systems {#filesystems}

#### Absolute and relative paths {#paths}

### Links {#links}

A *link* is a name of a file and is created with the `ln` command. Links can be either *hard* or
*symbolic* (*symlinks*) and a file can have many. The "normal" name you see for a file is a hard
link.

Links are created with the `ln` command (with the `-s` flag for symlinks), removed with the `rm`
command and moved, including name changed, with `mv`.

#### Hard links {#hard-links}

Every file must have at least one hard link, but can have many, all of them equivalent. This means
that a file can have many indistinguishable names. They must all reside on the same file system (see
\@ref(filesystems)). A file is not removed until you have removed all links. You can see this
behavior with the following example:

```
pushd /tmp      # cd to /tmp, but remember where I came from
touch l0        # Create an empty file
for i in {1..9}; do ln l0 l${i}; done   # Create 9 more hard links/names
ls -li l[0-9]   # -l is for long and -i shows the inode number
rm l0           # Remove the first created link
ls -li l[0-9]
rm l[0-9]
ls -li l[0-9]
popd            # cd back to where you were before pushd
```

Note that the first column of the file listing above, the *inode number*, is the same for all,
indicating that they point to the same *inode* and that third column of the first listing has a 10:
the number of links. After the first `rm` the number of links goes down to 9. The file does not
disappear until all links have been removed. In actual fact the *inode* remains until the space is
needed, when it can be removed.

#### Symbolic links -- *symlinks* {#symlinks}

A *symlink* can be thought of as a "shortcut" to a hard link, i.e. a file. Symlinks can reside on
another file system than the hard link it points to and removing one will never remove the file. For
all other purposes, symlinks are equivalent to hard links and can be very useful.

Why using symlinks instead of actual file copies?

1. Unlike file copies symlinks are mere labels, so that a considerable amount of disk memory can be
   saved.

1. They are a safety measure: in case you accidentally overwrite them the original file remains
   unaffected, thus preventing from losing valuable information. Commands which read or write file
   contents will access the contents of the target file. The rm (delete file) and mv (move)
   commands, however, affect the link itself, not the target file.

1. Symbolic links operate transparently: programs accept symlinks as input files, as long as they
   redirect to existing files, and they will behave as if operating directly on the target file.

```
pushd /tmp
touch a_file            # Create an empty file
ln -s a_file a_symlink  # Create a symlink pointing to it
ls -l a_file a_symlink  # List the two
rm a_file a_symlink     # Remove them
popd
```

Note in the row for `a_symlink` in the file listing, that there's an `l` in the first column of the
first field (the permissions) indicating this is a symlink, which is also shown at the end of the
line as `a_symlink -> a_file`.

### Timestamps {#timestamps}

## Editing files {#text-editors}

For almost any task you perform as a computational biologist, you need to edit \index{text
file}*text files*. If you're new to command line computing, the concept of a text file might be a
bit abstract -- are they Word documents? What's meant by *text file* in computing is not a file
containing text, like word processor documents, but files containing *only* text, i.e. files that do
not contain formatting information or any other fancy stuff -- with the exception of files like e.g.
HTML where the formatting itself is written as plain text -- just the text characters themselves.
The opposite to text files are \index{binary file}*binary files*, files with information, like
formatting, that requires a program for interpretation.

Examples of text files you will be exposed to are all your raw data in *fasta* or *fastq* format,
processed data in the form of *tab or comma separated tables* (in contrast to spreadsheet data,
which is binary), *program code* (e.g. R scripts) and *configuration files* for programs you run.

Since text files frequently need to be manipulated, you need to choose and learn a *text editor*, a
program to edit text files. There are usually several installed by default in any UNIX computer,
common examples include Vim, Nano and Emacs. There is probably some advantage to each of them, but
they can also be roughly divided into those that are a bit more intuitive to use, but usually less
powerful and those that have a steeper learning curve, but very powerful in the long run.

Since you're going to work a lot with text files, I encourage you to *choose either Vim or Emacs*!

### Nano {#nano}

One of the most common examples of the intuitive, less powerful editors is \index{Nano}Nano. You
start Nano with the following command, which will let you work with `my_file` by replacing the
command line with a view of the file:

```
nano my_file
```

As you can see, there's a line at the bottom giving you instructions for how to save the file, exit
the program etc. Besides that, editing a file is straightforward: you just use the arrow, PgUp and
PgDown keys to move around and the type text, press delete or backspace to change things.

### Vi/Vim {#vim}

\index{Vim}Vim^[**V**i **im**proved. The name comes from the fact that Vim was born as a
reimplementation of the classical, but non-free, UNIX text editor Vi (short for **vi**sual in
contrast to the line-oriented editors, primarily Ed, that existed before it).] is a popular example
of powerful text editors with quite a steep learning curve. Vim's power comes e.g. from the way you
can navigate and modify the text by using regular expressions (see \@ref(regexps)).

The primary reason for why Vim is difficult to begin with is that it has *two modes*: moving about
or *command* mode and *insert* mode respectively. When you're in moving about mode the keys have
completely different meaning than when you're in insert mode. In the latter, keys have the normal
meaning, i.e. pressing an "j" means inserting an "j" character at the position of the cursor. In
command mode, a "j" means move down one line.  

Pressing some keys will change mode from command to insert: An "i" will let you **i**nsert text at
the position of the cursor, an "o" will **o**pen a new line above the one you're standing and an "a"
will **a**pend (there are also capital versions of each of these, so be careful with &lt;shift&gt;.

To go from insert mode to command mode, you press &lt;Esc&gt;.

If you happen to open a file with Vim, don't know what to do and *just want to quit*, type `:q!` and
press &lt;Enter&gt;. This will **q**uit without saving. If you instead type `:x` you will e**x**it
*and save* if the file was modified.

Instead of writing yet another Vim tutorial, [here's one, rather randomly selected, tutorial series
for how to work with Vim](https://www.linux.com/learn/vim-101-beginners-guide-vim).

### Emacs {#emacs}

## Screen {#screen}

## Source control with Git {#git}

TO BE DONE.

[Link to nice blog post](https://nvie.com/posts/a-successful-git-branching-model/). (Not beginner
stuff though.)

## Installing programs with Conda {#conda}

Software installation varies according to the software, this is where package managers come in aid.
*Conda* is a python-based manager that handles software installation and update. Python knowledge is
not required in order to use it. With Conda you can:

1.Readily install a software and all its required dependencies at once.

1.Easily update the installed software.

1.store different versions of programs in different environments, because Conda is also an
environment manager.

### How to install Conda {#installing-conda}

*NOTE:* This is a bit long.

*Anaconda* is a science data platform based on the compiling language Python. Namely, *Conda* is
a system for the distribution of Python and also for the collection of more than one thousand
open-source packages therein present.  The quickest way to have Conda is to install *Miniconda*, a
reduced version of Anaconda that includes only Conda and its dependencies.  First, check the System
Requirements [here](https://conda.io/docs/user-guide/install/index.html#system-requirements).  if
one or more of the requirements are missing, you can install these packages by evoking the python
wrapper apt: 

``` 
apt install packagename 
``` 

Once you will have fulfilled all the system requirements you can download and install Miniconda from
[here](https://conda.io/miniconda.html).You need to choose a Miniconda installers suitable for your
operative system.  miniconda executive files contain the conda package manager and a Python version
between 3.6 (miniconda3) and 2.7 (Miniconda).  It is advisable to choose Miniconda3 as most of the
bioinformatics tools in use are compiled in Python 3 and are not correctly interpreted by one of the
versions of Python 2. Regardless, it is possible to have both Pyhton 3 and Python 2 in the same
operative system by creating separate environments with conda, as shown in the next chapter.  For
example, in order to get Miniconda3 for a LINUX environment of 64 bit, type: 

``` 
bash Miniconda3-latest-Linux-x86_64.sh 
``` 

you can know if conda has been correctly installed, and the number of the conda version, by typing: 

``` 
conda --version 
``` 

The following command updates the version of conda in use to the latest version
released: 

``` 
conda update conda 
```

### How to work with Conda {#working-with-conda}

Conda can install and manage the thousand packages and repositories that are collected in the
Anaconda database. 

The all-purpose command for installing programs with conda is:

``` 
conda install -c namechannel namepackage 
```

where the -c flag specifies the channel (e.g. namechannel) that contains said package
(e.g. namepackage). You can look for the channel that contains the package of interest in the [Anaconda Cloud](https://anaconda.org/).
A [tutorial](https://conda.io/docs/user-guide/tutorials/index.html) about how to set Conda and run it has been made available online.
Although conda works both with Python 2.7 and 3.6, only the version 3 is the one 
that is being currently updated. Furthermore, programs like CheckM will support only particular
versions of Python (e.g. 2.7 for CheckM), so sooner or later you might need to create a conda
environment that stores a specific version of a software (e.g. Python).
Suppose we have installed Miniconda3 and are interested in having both Python 2.7 and Python 3.6
available in the same account. The following command line creates a conda environment named python2.7
with Python version 2.7 installed in it:

```
conda create --name python2.7 python=2.7
```

An environment (i.e. environmentname) can be activated by typing `source activate environmentname`
Conversely, `source deactivate environmentname` deactivate an environment.  Check the name and
number of stored environments:

```
conda info --envs
```

To see which packages are installed in your current conda environment and their version numbers, run:

```
conda list
```

Note that conda will mark with an asterisk the currently active environment.

A list of the most useful commands can be found in the [Conda cheatsheet](https://conda.io/docs/user-guide/cheatsheet.html).
```{r include=FALSE}
# vim:tw=100
```
