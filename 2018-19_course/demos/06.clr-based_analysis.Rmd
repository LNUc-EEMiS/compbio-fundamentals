---
title: "Centered log ratio analysis of 16S data"
author: "daniel.lundin@lnu.se"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  pdf_document:
    fig_caption: yes
    fig_height: 9
    fig_width: 8
    number_sections: yes
    toc: yes
  html_document:
    toc: yes
---

```{r setup, echo=F, cache = FALSE}
knitr::opts_chunk$set(echo=F, fig.path='figures/', cache = TRUE)
ggplot2::theme_set(ggplot2::theme_bw())
```

```{r libraries, message=F, cache = FALSE}
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(kfigr))
suppressPackageStartupMessages(library(knitr))

# Packages needed to calculate clr
library(zCompositions)
library(CoDaSeq)
```

```{r constants}
```

```{r read-data}
# Read the ASV table and turn it long without zeroes
asvs <- read_tsv(
  '../../data/atacama-soils.asvtable.tsv',
  col_types = cols(.default = col_double(), seqid = col_character())
) %>%
  gather(sample, count, 2:67) %>%
  # Take away rows with zero count
  filter(count > 0) %>%
  # Take away samples with less than 500 observations
  group_by(sample) %>% filter(sum(count) >= 500) %>% ungroup()

# Read the taxonomy table
taxonomy <- read_tsv(
  '../../data/taxonomy.tsv',
  col_types = cols(
    .default = col_character(), Confidence = col_double()
  )
) %>%
  # Delete the D_0__ etc strings at the start of each taxon
  mutate(
    Taxon = gsub('D_[0-9]_+', '', Taxon)
  ) %>%
  # Rename Feature ID to seqid, the name in the ASV table
  rename(
    seqid = `Feature ID`,
  ) %>%
  # Separate th single taxonomy string into indvidiual taxa
  separate(
    Taxon, 
    c('domain', 'phylum', 'class', 'order', 'family', 'genus', 'species'), 
    sep = ';',
    fill = 'right'
  )

# Read the sample data ("metadata")
samples <- read_tsv(
  '../../data/sample_metadata.tsv',
  col_types = cols(
    .default = col_double(),
    SampleID = col_character(), BarcodeSequence = col_character(), LinkerPrimerSequence = col_character(),
    ExtractGroupNo = col_character(), TransectName = col_character(), SiteName = col_character(),
    Vegetation = col_character(), Description = col_character()
  )
)
```

# Centered Log Ratios

*C*entered *L*og *R*atios (clrs) are calculated as log of the ratio between a count and the geometric mean of counts in 
the sample:

$$
clr_s = \log{\frac{c_s}{\sqrt[n]{\prod_{i = 1}^{n} c_i}}}
$$

Where $n$ is the number of samples, $cls_s$ is the centered log ratio and $c_s$ the count respectively for sample $s$.

## Dealing with zeroes

The scary thing in the denominator, the geometric mean of the sample, i.e. root of the product of all counts in the sample,
will be zero if there's a single  zero, i.e. unobserved taxon (ASV), in a sample. The root
will then be zero and since division by zero is undefined, the clr will be too. Since a typical biological sequencing data
set always contains a lot of zeroes, clrs will typically be undefined for all samples. To use clr, the zeroes therefore
need to be removed or replaced with something else.

The zeroes are artefacts of sequencing depth, and *not evidence for the absence of a population* in a sample. Methods that
deal with zeroes can hence be based on estimation of the true count (<1) of a population or similar. The `cmultRepl()`
function in the `zCompositions` package can help us replace the zeroes with very small *pseudocounts* ("p-counts").

*** > Read the Palarea-Albaladejo 2013 paper! <

Terms:

* *left-censored*: a data point is below a certain value. In our case this means below detection limit given the sequencing
depth for the sample in question.

```{r calc-clr}
# This adds a clr column to the asvs table.
# Note that the assignment to "asvs" is last and uses the -> assignment operator.
# Since all combinations of sample and seqid will now get a value, clr, the number of rows increases quite a lot.
asvs %>%
  # Make the table wide with samples as columns
  spread(sample, count, fill = 0) %>%
  # Move the seqid to rowname; this requires a data.frame()
  data.frame() %>% tibble::column_to_rownames('seqid') %>%
  # Replace zeroes with probabilities (pseudocounts) (I needed a slightly lower delta than default not to get negative values)
  cmultRepl(method = 'CZM', delta = 0.5, output = 'p-counts') %>%
  # Calculate the CLR
  codaSeq.clr(samples.by.row = FALSE) %>%
  data.frame() %>%
  tibble::rownames_to_column('sample') %>%
  gather(seqid, clr, 2:ncol(.)) %>%
  # Get rid of 'X' that sometimes precedes the seqid and join back with original table
  mutate(seqid = sub('^X', '', seqid)) %>%
  left_join(asvs, by = c('sample', 'seqid')) %>%
  # Set count to 0 if it's NA
  replace_na(list(count = 0)) -> asvs
```

## Some characteristics of clrs

Centered log ratios do not sum to the same sum for all samples -- in fact, they sum to many orders of magnitude different
values `r figr('clrsum-plot', T, type = 'Figure')` -- and they are often
negative (beacuse one takes the log). They are hence not good replacements for relative abundances in e.g. heatmaps.

```{r clrsum-plot, fig.height=6, fig.cap = 'Per sample sums of centered log ratios.'}
asvs %>%
  group_by(sample) %>% summarise(clrsum = sum(clr)) %>% ungroup() %>%
  ggplot(aes(x = sample, y = clrsum)) +
  geom_point() +
  coord_flip()
```

```{r}
asvs %>%
  group_by(sample) %>% mutate(relclr = clr/sum(clr)) %>% ungroup()
```


